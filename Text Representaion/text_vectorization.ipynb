{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BoW (bag of words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love the new design of your website</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The product is terrible and disappointing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazing experience, I will come again</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very bad service and rude staff</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I am happy with the quick delivery</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        text  label\n",
       "0      I love the new design of your website      1\n",
       "1  The product is terrible and disappointing      0\n",
       "2      Amazing experience, I will come again      1\n",
       "3            Very bad service and rude staff      0\n",
       "4         I am happy with the quick delivery      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    \"text\": [\n",
    "        \"I love the new design of your website\",         \n",
    "        \"The product is terrible and disappointing\",     \n",
    "        \"Amazing experience, I will come again\",         \n",
    "        \"Very bad service and rude staff\",               \n",
    "        \"I am happy with the quick delivery\"],\n",
    "    \"label\": [1,0,1,0,1]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = cv.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 1 0 0 1]]\n",
      "[[0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0]]\n",
      "[[1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(bow[0].toarray())\n",
    "print(bow[1].toarray())\n",
    "print(bow[2].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#problem of unseen words is handled in bow! it ignores the words is not in the trained vocabulory\n",
    "ex = cv.transform(['raj is happy,because he love this design'])\n",
    "ex[0].toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'love the': 10, 'the new': 18, 'new design': 11, 'design of': 6, 'of your': 12, 'your website': 24, 'the product': 19, 'product is': 13, 'is terrible': 9, 'terrible and': 17, 'and disappointing': 2, 'amazing experience': 1, 'experience will': 7, 'will come': 22, 'come again': 5, 'very bad': 21, 'bad service': 4, 'service and': 16, 'and rude': 3, 'rude staff': 15, 'am happy': 0, 'happy with': 8, 'with the': 23, 'the quick': 20, 'quick delivery': 14}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#it works like i love data\n",
    "#bigram range (1,2) = ['i','love','data','i love','love data'] combination of bow and bigram\n",
    "#bigram range (2,2) = ['i love','love data'] bigram\n",
    "#if we tell the range (4,4) but the sentence dont have 4 words the vocabulaory will not be created\n",
    "ngrams = CountVectorizer(ngram_range=(2,2))\n",
    "bigrams = ngrams.fit_transform(df['text'])\n",
    "print(ngrams.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams[0].toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trigrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'love the new': 15, 'the new design': 25, 'new design of': 17, 'design of your': 7, 'of your website': 19, 'love the new design': 16, 'the new design of': 26, 'new design of your': 18, 'design of your website': 8, 'the product is': 27, 'product is terrible': 20, 'is terrible and': 13, 'terrible and disappointing': 24, 'the product is terrible': 28, 'product is terrible and': 21, 'is terrible and disappointing': 14, 'amazing experience will': 2, 'experience will come': 9, 'will come again': 32, 'amazing experience will come': 3, 'experience will come again': 10, 'very bad service': 30, 'bad service and': 5, 'service and rude': 22, 'and rude staff': 4, 'very bad service and': 31, 'bad service and rude': 6, 'service and rude staff': 23, 'am happy with': 0, 'happy with the': 11, 'with the quick': 33, 'the quick delivery': 29, 'am happy with the': 1, 'happy with the quick': 12, 'with the quick delivery': 34}\n"
     ]
    }
   ],
   "source": [
    "grams = CountVectorizer(ngram_range=(3,4))\n",
    "trigrams = grams.fit_transform(df['text'])\n",
    "print(grams.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "        0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigrams[0].toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.39379499, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.39379499, 0.39379499, 0.39379499,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.26372909, 0.        , 0.39379499, 0.        ,\n",
       "        0.        , 0.39379499],\n",
       "       [0.        , 0.        , 0.        , 0.35727423, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.4428322 , 0.        ,\n",
       "        0.        , 0.4428322 , 0.        , 0.        , 0.        ,\n",
       "        0.4428322 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.4428322 , 0.29656989, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.4472136 , 0.        , 0.4472136 , 0.        , 0.        ,\n",
       "        0.4472136 , 0.        , 0.        , 0.        , 0.4472136 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.4472136 ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.33939315, 0.42066906,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.42066906, 0.42066906, 0.42066906,\n",
       "        0.        , 0.        , 0.42066906, 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.42841136, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.42841136, 0.        , 0.        , 0.        ,\n",
       "        0.42841136, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.42841136, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.28691208, 0.        , 0.        , 0.        ,\n",
       "        0.42841136, 0.        ]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.fit_transform(df['text']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_df = pd.DataFrame({\n",
    "    'words':tfidf.get_feature_names_out(),\n",
    "    'tf-idf':tfidf.idf_\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>tf-idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>again</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>am</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazing</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and</td>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bad</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>come</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>delivery</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>design</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>disappointing</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>experience</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>happy</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>is</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>love</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>new</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>of</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>product</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>quick</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>rude</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>service</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>staff</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>terrible</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>the</td>\n",
       "      <td>1.405465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>very</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>website</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>will</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>with</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>your</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            words    tf-idf\n",
       "0           again  2.098612\n",
       "1              am  2.098612\n",
       "2         amazing  2.098612\n",
       "3             and  1.693147\n",
       "4             bad  2.098612\n",
       "5            come  2.098612\n",
       "6        delivery  2.098612\n",
       "7          design  2.098612\n",
       "8   disappointing  2.098612\n",
       "9      experience  2.098612\n",
       "10          happy  2.098612\n",
       "11             is  2.098612\n",
       "12           love  2.098612\n",
       "13            new  2.098612\n",
       "14             of  2.098612\n",
       "15        product  2.098612\n",
       "16          quick  2.098612\n",
       "17           rude  2.098612\n",
       "18        service  2.098612\n",
       "19          staff  2.098612\n",
       "20       terrible  2.098612\n",
       "21            the  1.405465\n",
       "22           very  2.098612\n",
       "23        website  2.098612\n",
       "24           will  2.098612\n",
       "25           with  2.098612\n",
       "26           your  2.098612"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
